<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css">
    <title>Referencias</title>
</head>
<body>
    <p><a href="index.html">&laquo; Índice</a></p>
    <h1>Referencias</h1>
    <ul>
        <li id="ref1">[1] J. V. Arenales, "Así es el avance en 30 construcciones de vías 4G y 5G que se adelantan en Colombia",
            La República, Julio. 24, 2023. [Online]. Available: 
            https://www.larepublica.co/economia/este-es-el-avance-en-la-construccion-de-las-vias-4g-y-5g-del-pais-3663422
        </li>
        <li id="ref2">[2] Agencia Nacional de Seguridad Vial, Víctimas por siniestros viales clasificadas por tipo de vía, Sitio web. Disponible: 
            https://ansv.gov.co/es/observatorio/estadísticas/victimas-por-siniestros-viales-clasificadas-por-tipo-de.
        </li>
        <li id="ref3">[3] R. Huincalef, G. Urrutia, G. Ingravallo, and D. C. Martínez, “Recognition of Surface Irregularities on Roads: a machine learning 
            approach on 3D models” 2018.
        </li>
        <li id="ref4">[4] Molina Truyot, D. A., Taborda Jaramillo, P. A., & Maya Restrepo, L. S. (2024). Healthy road: Controla el futuro de tus carreteras. 
            Trabajo no publicado, [Universidad Nacional de Colombia -  Sede Medellín]
        </li>
        <li id="ref5">[5] "Bluehost: ¿qué es y cómo funciona? Ventajas y desventajas de usarlo," Rock Content, 21-Jun-2023. [Online]. Available: 
            https://rockcontent.com/es/blog/bluehost/#:~:text=Bluehost%20es%20un%20servicio%20de,a%20buena%20relación%20costo-beneficio.
        </li>
        <li id="ref6">[6] "Bluehost offers storage options in both shared hosting and VPS or dedicated servers, allowing users to host both the 
            frontend and backend of their applications in the same environment," Bluehost. [Online]. Available: https://www.bluehost.com.
        </li>
        <li id="ref7">[7] "Managing Databases with Applications," Bluehost. [Online]. Available: 
            https://www.bluehost.com/help/article/managing-databases-with-applications.
        </li>
        <li id="ref8">[8] PyTorch, "Tensors", PyTorch Documentation, 2024. [Online]. Available: https://pytorch.org/docs/stable/tensors.html. 
        </li>
        <li id="ref9">[9] J. Murata et al., "RDD2022 - The multi-national Road Damage Dataset released through CRDDC 2022," Figshare, Dataset, 2022. 
            [Online]. Available: https://figshare.com/articles/dataset/RDD2022_-_The_multi-national_Road_Damage_Dataset_released_through_CRDDC_2022/21431547/1?file=38030910. 
        </li>
        <li id="ref10">[10] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, 
            S. Gelly, J. Uszkoreit, y N. Houlsby, "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale," arXiv preprint arXiv:2010.11929, 
            2020. [En línea]. Disponible en: https://arxiv.org/abs/2010.11929.
        </li>
        <li id="ref11">[11] C. Olah et al., "Attention and Transformers," Distill.pub, 2021. [En línea]. Disponible en: https://distill.pub/2021/multi-head/.
        </li>
        <li id="ref12">[12] "PyTorch Vision Transformer Implementations," PyTorch. [En línea]. Disponible en: https://pytorch.org/vision/stable/models.html.
        </li>
        <li id="ref13">[13] "Vision Transformer Model Documentation," Hugging Face Documentation. [En línea]. Disponible en: 
            https://huggingface.co/docs/transformers/model_doc/vit.
        </li>
        <li id="ref14">[14] A. Karpathy y F. Li, "CS231n: Convolutional Neural Networks for Visual Recognition," Stanford University, 2019. 
            [En línea]. Disponible en: http://cs231n.stanford.edu/.
        </li>
        <li id="ref15">[15] A. Ng, "Deep Learning for Computer Vision," Coursera. [En línea]. Disponible en: 
            https://www.coursera.org/learn/convolutional-neural-networks.
        </li>
        <li id="ref16">[16] Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). You Only Look Once: Unified, Real-Time Object Detection. 
            IEEE Conference on Computer Vision and Pattern Recognition (CVPR).
        </li>
        <li id="ref17">[17] Zhu, X., Liu, Y., Liu, S., et al. (2021). YOLOv4: Optimal Speed and Accuracy of Object Detection. 
            IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI).
        </li>
    </ul>
    <p><a href="index.html">&laquo; Índice</a></p>
</body>
</html>